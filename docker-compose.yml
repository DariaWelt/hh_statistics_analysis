version: '2'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    networks:
      - hh_analyzer
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 2181:2181
  
  kafka:
    image: confluentinc/cp-kafka:latest
    networks:
      - hh_analyzer
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT_INTERNAL://kafka:29092,PLAINTEXT://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  db:
    image: mongo:4.0.8
    restart: unless-stopped
    networks:
      - hh_analyzer
    environment:
      MONGO_INITDB_DATABASE: hh_vacancies
      MONGODB_DATA_DIR: /data/db
      MONDODB_LOG_DIR: /dev/null
    ports:
      - 27017:9200
    volumes:
      - mongodbdata:/data/db

  extractor:
    build:
      context: ./hh_analyzer/
      dockerfile: ./ExtractorDockerfile.dockerfile
    networks:
      - hh_analyzer
    depends_on:
      - db
      - kafka
    environment:
      HHS_DB_URI: mongodb://db
      HHS_DATABASE_NAME: hh_vacancies
      HHS_EXTRACTOR_KAFKA_THEME: extract
      HHS_KAFKA_PORT: kafka:29092
    volumes:
      - ./extractor_logs/:/log/
      - ./hh_analyzer/ServisesUtils:/ServisesUtilsdocke

#  user_app:
#    build: ./hh_analyzer/UserApp
#    environment:
#      HHS_DB_URI: mongodb://db
#      HHS_DATABASE_NAME: hh_vacancies
#      HHS_EXTRACTOR_KAFKA_THEME: extract
#    volumes:
#      - frontend:/app
#    ports:
#      - 8900:8900

  pyspark:
    image: apache/spark-py
    container_name: handler
    user: root
    volumes: 
      - ./hh_analyzer/Handler:/opt/spark/work-dir
    ports:
      - 19090:19090
    entrypoint: /opt/spark/work-dir/main.sh
    enviroment:
      - DB_URL: mongodb://db
      - DB_NAME: hh_vacations
      - DB_COLLECTION: hh_vacancies_RAW
      - SPARK_APP: /opt/spark/work-dir/hmain.py 

      - SEND_TOPIC: processing
      - RESP_SEND_TOPIC: resp_processing
      - KAFKA_DOM: kafka:9092

volumes:
  mongodbdata:
  extractor_logs:
  frontend:
  pyspark:

networks:
  hh_analyzer:
    driver: bridge